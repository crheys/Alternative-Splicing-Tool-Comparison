#!/bin/bash
#SBATCH --time=60:00:00
#SBATCH --nodes=1
#SBATCH --cpus-per-task=32
#SBATCH --mem=128G
#SBATCH --output=%j-%x.out
#SBATCH --error=%j-%x.err

# === CONFIGURATION ===
WHIPPET_BIN="/mainfs/scratch/ch5g20/RESEARCH_PROJECT/Whippet.jl/bin"
INDEX="/mainfs/scratch/ch5g20/RESEARCH_PROJECT/COMPARISON/reference/GRCh38.p14/whippet_index.jls"
AS_DIR="/mainfs/scratch/ch5g20/RESEARCH_PROJECT/COMPARISON/HD/AS_analysis"
OUTPUT_DIR="/mainfs/scratch/ch5g20/RESEARCH_PROJECT/COMPARISON/HD/AS_analysis/whippet"
FASTQ_DIR="/mainfs/scratch/ch5g20/RESEARCH_PROJECT/COMPARISON/HD/filtering"

#Define sample groups
GROUP_A_SAMPLES=(
    "SRR3306823"
    "SRR3306824"
    "SRR3306825"
    "SRR3306826"
    "SRR3306827"
    "SRR3306828"
    "SRR3306829"
)
GROUP_B_SAMPLES=(
    "SRR3306830"
    "SRR3306831"
    "SRR3306832"
    "SRR3306833"
    "SRR3306834"
    "SRR3306835"
    "SRR3306836"
)


# === FUNCTIONS ===

#Run whippet quant on all samples
run_quant() {
    SAMPLE=$1
    R1="$FASTQ_DIR/${SAMPLE}_R1_paired.fastq.gz"
    R2="$FASTQ_DIR/${SAMPLE}_R2_paired.fastq.gz"
    OUT="$OUTPUT_DIR/quant/$SAMPLE"

    echo "Running whippet-quant for $SAMPLE..."
    export JULIA_NUM_THREADS=$SLURM_CPUS_PER_TASK
    julia "$WHIPPET_BIN/whippet-quant.jl" \
        <(zcat "$R1" | awk -v count=0 '++count==3{$0="+";count=-1} 1') \
        <(zcat "$R2" | awk -v count=0 '++count==3{$0="+";count=-1} 1') \
        -x "$INDEX" \
        -o "$OUT" \
        --sam > /dev/null 2>&1
}

run_all_quant() {
    echo "== Running Whippet Quantification =="
    for SAMPLE in "${GROUP_A_SAMPLES[@]}" "${GROUP_B_SAMPLES[@]}"; do
        run_quant "$SAMPLE"
    done
}

#Run whippet delta on .psi files generated by whippet quant
run_delta() {
    echo "== Running Whippet Delta =="
    A_FILES=$(printf "%s.psi.gz," "${GROUP_A_SAMPLES[@]/#/$OUTPUT_DIR/quant/}")
    B_FILES=$(printf "%s.psi.gz," "${GROUP_B_SAMPLES[@]/#/$OUTPUT_DIR/quant/}")
    A_FILES="${A_FILES%,}"
    B_FILES="${B_FILES%,}"

    julia "$WHIPPET_BIN/whippet-delta.jl" \
        -a "$A_FILES" \
        -b "$B_FILES" \
        -o "$OUTPUT_DIR/delta/output"
}

#Filter output for significant events and split events into files based on event type
filter_and_split_events() {
    echo "== Filtering and Splitting Significant Events =="
    mkdir -p "$OUTPUT_DIR/events"

    zcat "$OUTPUT_DIR/delta/output.diff.gz" | awk '
    BEGIN { OFS="\t" }
    NR==1 { header=$0; next }
    ($9 >= 0.95 && ($8 > 0.1 || $8 < -0.1)) {
        file = "'"$OUTPUT_DIR"'/events/filtered_" $5 ".diff"
        if (!(file in seen)) {
            print header > file
            seen[file] = 1
        }
        print >> file
    }
    '

# Combine all significant events into one file
    echo "Creating combined file of all significant events..."
    zcat "$OUTPUT_DIR/delta/output.diff.gz" | awk '
    BEGIN { OFS="\t" }
    NR==1 { print; next }
    ($9 >= 0.95 && ($8 > 0.1 || $8 < -0.1)) { print }
    ' > "$OUTPUT_DIR/events/filtered_all_events.diff"
}


# === MAIN PIPELINE ===

mkdir -p "$AS_DIR" "$OUTPUT_DIR" "$OUTPUT_DIR/quant" "$OUTPUT_DIR/delta" "$OUTPUT_DIR/events"

run_all_quant
run_delta
filter_and_split_events

echo "== Pipeline Complete =="
